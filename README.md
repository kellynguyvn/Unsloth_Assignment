# Unsloth Assignments 
### Tuning and experimenting with llms

## Deliverables
### a) Finetuning : finetune with following open weights llm modules:
  - Mistral NeMo (12B)
  - Gemma 2 (9B)
  - Inference chat UI
  - Phi-3.5 (mini)
  - Llama 3 (8B)
  - Mistral v0.3 (7B)
  - Phi-3 (medium)
  - Qwen2 (7B)
  - Gemma 2B
  - TinyLlama <br>
### b) Continued pretraining: use unsloth ai to make llm learn a new language
### c) Do Chat templates colabs for classification, conversational chat, extending max context size of tinyllama, multiple data sets single finetuning
### d) Do reward modeling colab with orpo and colab with dpo
### e) do continued fine tuning from custom checkpoint usecase 
### f) finetune unsloth for mental health development chatbot
### g) use unsloth to finetune a model and export to ollama and show inference

## Demos
Found in Folders

